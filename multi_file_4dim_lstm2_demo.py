# -*- coding: utf-8 -*-
from __future__ import print_function

"""Multi_file_4dim_lstm2_demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12peRIrKKwgbfWx06oCn8zSHhK_1LyPTq

# **MODULES**
Import statements need for the neural network.
The main modules for this file include:


1.   sci-kit learn: Used for scaling and splitting the data.
2.   pandas: Framework for interacting with the data.
3.   numpy: scientific package commonly used in deep learning.
4.   matplotlib: Plotting the error values and accuracy curves.
5.   PyTorch: necessary for the LSTM network used to predict the time-series data.
"""

import math
import sklearn as sk
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.ticker as ticker
import matplotlib.pyplot as plt
import os
import warnings
warnings.filterwarnings('ignore') # suppresses warnings in the MinMaxScaler()

from os.path import exists
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from pandas import concat
from tqdm import tqdm, tqdm_notebook # progress bar useful for iterating through data structures


torch.manual_seed(1)

"""# Google Cloud 
Necessary for interacting with the data found in google drive.
"""

# from google.colab import drive
# from google.colab import files
# drive.mount('/content/drive')
# BASE_DIR = '/content/drive/My Drive/SmartCity Research/Python Notebooks/'

# Extra experimental stuff
# source: https://www.machinelearningplus.com/python/parallel-processing-python/
import multiprocessing as mp
print("Number of processors: ", mp.cpu_count())

"""# CUDA 

Identifies the hardware device of the runtime instance.
"""

use_cuda = torch.cuda.is_available()
device = torch.device('cuda' if use_cuda else 'cpu')
use_parallel = False
device_count = torch.cuda.device_count()


print("use_cuda = ", use_cuda)
print(device_count)
print("device_count %s" % device_count)

"""# **SEQUENCE CLASS**

This class is derived from the pytorch example on the [pytorch github](https://github.com/pytorch/examples/blob/master/time_sequence_prediction/train.py). This class takes in a sequence of time series data and inputs it into 2 LSTM cells bassed on the nn pytorch module.

The `Sequence` class does not take in any parameters as of yet. However, there LSTM cells has a few hardcoded parameters such as the `input_dim` and `hidden_dim`. in this case, the `input_dim` = 4 which corresponds to the number of features that is taken into account. Initially, the example from the PyTorch github above was only one dimensional since it took in a single feature (x coordinates). I've expanded feature set to be multi-dimensional and in this example I've chosen 4 features in total as a start.
"""

class Sequence(nn.Module):
    def __init__(self):
#     def __init__(self, input_dim, hidden_dim):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(4, 51)
#         self.lstm1 = nn.LSTMCell(input_dim, hidden_dim)
        self.lstm2 = nn.LSTMCell(51, 51)
#         self.lstm2 = nn.LSTMCell(hidden_dim, hidden_dim)
        self.linear = nn.Linear(51, 4)
#         self.linear = nn.Linear(hidden_dim, input_dim)

    def forward(self, input, future = 0):
        outputs = []
#         print('input_size',input.size())
        h_t = torch.zeros(input.size(1), 51, dtype=torch.double, device=device)
        c_t = torch.zeros(input.size(1), 51, dtype=torch.double, device=device)
        h_t2 = torch.zeros(input.size(1), 51, dtype=torch.double, device=device)
        c_t2 = torch.zeros(input.size(1), 51, dtype=torch.double, device=device)
#         h_t = torch.zeros(input.size(1), hidden_dim, dtype=torch.double, device=device)
#         c_t = torch.zeros(input.size(1), hidden_dim, dtype=torch.double, device=device)
#         h_t2 = torch.zeros(input.size(1), hidden_dim, dtype=torch.double, device=device)
#         c_t2 = torch.zeros(input.size(1), hidden_dim, dtype=torch.double, device=device)
# #       
        #         print('chunk', input.chunk(input.size(0), dim=1))
#         for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
        for input_t in tqdm(input, desc='LSTM forward'):
#             print('input_t shape', input_t.shape)
#             print('input_t', input_t)
#             print('h_t', h_t.shape)
#             print('h_t', h_t)
#             print('c_t', c_t.shape)
#             print('c_t', c_t)
#             print('h_t,c_t', (h_t,c_t))
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))

            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in tqdm(range(future), desc='LSTM predict'):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs

"""# **Data**

This file demos the adaption of previous single-dimension LSTM to mulit-dimensional LSTM for multi-step predictions. The data I used contains completely random values so as I can illustrate that the multi-dimension LSTM training and prediction works. The predictions are not meant to be useful. 

The dimensions of the input `data` is (`batch_size`, `time_steps`,  `num_features`); in this case (100, 1000, 4).

# **Helper Functions**


*   `traverse_dir`: Identifies all file names in the directory.

> Parameters:
> -   `dir_name`: string for the directory for all file names to be 
> -   `return`: list of strings for filenames within the directory

*   `prepare_df`: Converts `.csv` file into 2 dataframes; `test` and `train`.

> Parameters:
> -   `path`: string for reading in a particular .csv file
> -   `return`: train and test sets as dataframes

*   `normalize_df`: Uses the `sklearn` `MinMaxScaler()` object to scale the raw values to the range `[0,1]`.

> Parameters:
> -   `dataframe`: dataframe to be normalized 
> -   `return`: dataframe that's normalized, sklearn scaler used

*   `inverse_normalize_df`: Uses the given `sklearn` `MinMaxScaler()` object to inverse the scaling done on the dataframe.

> Parameters:
> -   `dataframe`: dataframe to be de-normalized
> -   `scaler`: sklearn scaler associated with the dataframe to be de-normalized
> -   `return`: dataframe that's de-normalized
 
*   `get_data`: Calls on the helper functions `prepare_df` and `normalize_df` to convert `.csv` files into `torch.tensor` objects.

> -   Parameters:
>  -   `dir_path`: dataframe to be de-normalized
>  -   `file_names`: list of strings of file names for given data type.
>  -   `train_size`: Integar number of  time-steps per file for training set.
>  -   `test_size`: Integar number of  time-steps per file
>  -   `return`: `torch` objects representing 3D matrix of dim `[batch_size, time_steps,num_features]`
        - `train_tensor`: 
        - `target_tensor`:
        - `test_tensor`:
        - `test_target_tensor`:

*   `prepare_tensors`

> -   Parameters:
>  -   `train_norm`: dataframe to be de-normalized
>  -   `target_norm`: sklearn scaler associated with the dataframe to be de-normalized
>  -   `test_norm`: sklearn scaler associated with the dataframe to be de-normalized
>  -   `test_target_norm`: sklearn scaler associated with the dataframe to be de-normalized
>  -   `return`: dataframe that's de-normalized

*   `show_feature_plot`
"""

def traverse_dir(dir_name):
  file_names = []
  for dirName, subdirList, fileList in os.walk(dir_name):
      for fname in fileList:
          file_names.append(fname)
  return file_names

def prepare_df(path, col_names):
    df = pd.read_csv(path, names=col_names, engine='python')
    train = df.iloc[1: 2* len(df)//3]
    test = df.iloc[2 *len(df)//3:]
    return train, test

def normalize_df(dataframe):
    scaler = MinMaxScaler()
#     print(dataframe)
    dataframe = dataframe.iloc[1:,:]
    df_norm = scaler.fit(dataframe)
    df_norm = scaler.transform(dataframe)
#     df_norm = (dataframe - dataframe.mean()) / (dataframe.max() - dataframe.min()+1)
    return df_norm.astype(np.double, copy=False), scaler

def inverse_normalize_df(dataframe, scaler):
    dataframe = scaler.inverse_transform(dataframe)
    return dataframe

# Maybe parallelize this? This seems like a bottle neck for many files

# def get_data(dir_path, file_names, train_size, test_size, col_names):
def get_data(dir_path, file_names, train_size, test_size,col_names, start, end):

  train_array = []
  target_array = []
  test_array = []
  test_target_array = []

  
  for name in tqdm(file_names, desc='Getting data from filenames...'):
      train, test = prepare_df(dir_path+name, col_names)
      
#       train_trunc = train.iloc[len(train)-train_size:,2:6] 
      train_trunc = train.iloc[len(train)-train_size:,start:end] 
#       test_trunc = test.iloc[:test_size,2:6]
      test_trunc = test.iloc[:test_size,start:end]
#       train_norm, tr_scaler = normalize_df(train_trunc, tr_scaler)
#       test_norm, ts_scaler = normalize_df(test_trunc, ts_scaler)
#       
#       target = train.iloc[1:train_size+1, 2:6]
      target = train.iloc[1:train_size+1, start:end]
#       test_target = test.iloc[1:test_size+1, 2:6]
      test_target = test.iloc[1:test_size+1, start:end]
#       target_norm, tr_target_scaler = normalize_df(target, tr_target_scaler)
#       test_target_norm, ts_target_scaler = normalize_df(test_target, ts_target_scaler)
      # append doesn't happen in place
#       train_array = train_array.append(train_trunc)
#       target_array = target_array.append(target)
#       test_array = test_array.append(test_trunc)
#       test_target_array = test_target_array.append(test_target)
#       print("train_trunc", train_trunc)
#       print("train_shape", train_trunc.shape)
      train_array.append(train_trunc.values)
      target_array.append(target.values)
      test_array.append(test_trunc.values)
      test_target_array.append(test_target.values)
      # print(train_array)
      
  print('train_array', train_array) 
  train_df = pd.DataFrame(train_array)
  target_df = pd.DataFrame(target_array)
  test_df = pd.DataFrame(test_array)
  test_target_df = pd.DataFrame(test_target_array)
  return train_df, target_df, test_df, test_target_df

def prepare_tensors(train_norm, target_norm, test_norm, test_target_norm):

  # If the train_norm is using minmax scaler
#     train_tensor = torch.from_numpy(train_norm).to(device=device)
#     target_tensor = torch.from_numpy(target_norm).to(device=device)
#     test_tensor = torch.from_numpy(test_norm).to(device=device)
#     test_target_tensor = torch.from_numpy(test_target_norm).to(device=device)
    train_tensor = torch.tensor(train_norm).to(device=device)
    target_tensor = torch.tensor(target_norm).to(device=device)
    test_tensor = torch.tensor(test_norm).to(device=device)
    test_target_tensor = torch.tensor(test_target_norm).to(device=device)
    
    return train_tensor, target_tensor, test_tensor, test_target_tensor

"""# Initialization of Network and Parameters

Initial parameters for the network include:
> - `INPUT_DIM`: The number of features (attributes/columns of the data set) used in the neural network.
> - `HIDDEN_DIM`: The number of features within the network layers. Default value is equivalent to `INPUT_DIM` for simplicity. (Need stronger citation/justification)
> - `BATCH_SIZE`: The number of time steps for a particular batch training set.
> - `TEST_SIZE`: The number of time steps for a particular batch's test sample set.

*NOTE: * For the initial trial of this network, there are hard coded values for these parameters. Sometimes if the dataset does not contain enough time-steps than then the parameters `BATCH_SIZE` and `TEST_SIZE` will have to be adjusted to the number of max time steps in the data sample. 

By default the `Sequence` class is cast to `double` in order for the matrix mulitplication to have all the same `numpy` primitive types. 

## Loss Criterion
**Mean Square Error** is commonly used in regression-like tasks similar to what this neural network aims to achieve in multi-step time-step prediction.  Other loss criterion may be used and their accuracies compared in, future work.

### Output Note
"""

# Global parameters
NUM_FILES = 100
# BASE_DIR = '/content/drive/My Drive/SmartCity Research/'
# BASE_DIR = '/content/drive/My Drive/SmartCity Research/'
# DIR = 'Edge Data/edge_data-12-45-52-March-18-2019/'
DIR = '2019-03-20-19-32-29/edge_data-1000-10000-02-02-53-April-15-2019/' # Needs trailing slash at the end
file_names = traverse_dir(DIR)[:NUM_FILES]

# names = ['step', 'street_name', 'co', 'co2', 'noise', 'num_veh','ped','hc_emission','nox_emission']
names = ['step','street_name','noise', 'num_veh', 'num_lane', 'wait_time', 'occupancy', 'fuel', 'electricity', 'co','co2', 'hc', 'nox', 'pmx', 'ped']

# Init Network and Parameter Objects 
# seq = Sequence()
# seq = Sequence(input_dim=INPUT_DIM,hidden_dim=HIDDEN_DIM)
# seq.double()

# Network Parameters
INPUT_DIM = 11
HIDDEN_DIM = 11
BATCH_SIZE = 100
TEST_SIZE = 100
NUM_EPOCHS = 5
FUTURE = 10
START = 2 # Start column index of data
END = 13 # End column index of data
tr_scaler = MinMaxScaler()
ts_scaler = MinMaxScaler()
tr_target_scaler = MinMaxScaler()
ts_target_scaler = MinMaxScaler()

training_data, target_data, test_data, test_target_data = get_data(DIR, file_names, BATCH_SIZE, TEST_SIZE, names,START, END)

print('train_tensor.shape',training_data.shape)
print('train_tensor',training_data)
print('target.shape',target_data.shape)
print('target',target_data)
print('test_input.shape',test_data.shape)
print('test',test_data)
print('test_target.shape',test_target_data.shape)
print('test_target',test_target_data)

print(type(training_data))
print(type(target_data))
print(type(test_data))
print(type(test_target_data))
# train_tensor = torch.from_numpy(training).to(device=device)

# Normalize
training_data_norm, tr_scaler = normalize_df(training_data)
target_data_norm, tr_target_scaler = normalize_df(target_data)
test_data_norm, ts_scaler = normalize_df(test_data)
test_target_data_norm, ts_target_scaler = normalize_df(test_target_data)

type(training_data_norm[0])
print(training_data_norm.shape)
print(training_data_norm)

train_tensor, target_tensor, test_tensor, test_target_tensor = prepare_tensors(training_data_norm[0], target_data_norm[0], test_data_norm[0], test_target_data_norm[0]) 
#

print('train_tensor.shape',train_tensor.shape)
print('train_tensor',train_tensor)
print('target.shape',target_tensor.shape)
# print('target',target)
print('test_input.shape',test_tensor.shape)
# print('test',test)
print('test_target.shape',test_target_tensor.shape)
# print('test_target',test_target)

"""# **Training**

Training involves the use of the `closure()` method which is a parameter fed into the `optimizer.step()` [function](https://pytorch.org/docs/stable/optim.html#optimizer-step-closure).  
As per PyTorch documentation 
```
Some optimization algorithms such as Conjugate Gradient and LBFGS need to reevaluate the function multiple times, so you have to pass in a closure that allows them to recompute your model. The closure should clear the gradients, compute the loss, and return it.
```

## Predictions

Predictions are generated per epoch, as per the example on [PyTorch github](https://github.com/pytorch/examples/blob/master/time_sequence_prediction/train.py). Here there are hard coded values for the number of steps to predict. In this ase the parameters are:
1.   Epochs: 5
2.   Future Time steps: 100
"""

def train(num_epochs, train_tensor, target_tensor, model, optimizer, hist):
  for epoch in tqdm(range(num_epochs),desc = 'train()...'):
    for train_input, target_input in zip(train_tensor, target_tensor):
#       print(train_input)
#       print(target_input)
      # Step 1. clear out accumulated PyTorch gradients
      model.zero_grad()
      # optimizer.zero_grad() # not sure if this is needed
      # clear out hidden states of the LSTM
      model.hidden = model.init_hidden()

      # Step 2. Run our forward pass
      y_pred = model(train_tensor)

      # Step 3. Compute the loss, gradients and update the parameters by 
      # calling optimizer.step()
      loss = loss_function(y_pred, target_input.view(-1))

      hist[epoch] = loss.item()

      # Backward pass
      loss.backward()
#       print('loss:', loss.item())

      # Update parameters
      optimizer.step()

class LSTMTimeSeries(nn.Module):
  def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1, 
               num_layers=1):
    super(LSTMTimeSeries, self).__init__()
    self.hidden_dim = hidden_dim
    self.input_dim = input_dim
    self.batch_size = batch_size
    self.num_layers = num_layers
    
    # LSTM takes the time series steps as input, and outputs hidden states
    # with dimensionality hidden_dim
    self.lstm = nn.LSTM(input_dim, hidden_dim, self.num_layers)
    
    # We need a linear layer that maps the hidden state space to the predicted
    # state space
    
    self.linear = nn.Linear(self.hidden_dim, output_dim)
    
  def init_hidden(self):
    # We don't have any hidden state, until we init
    return (torch.zeros(self.input_dim, self.hidden_dim, self.hidden_dim,device=device),
            torch.zeros(self.input_dim, self.hidden_dim, self.hidden_dim,device=device))
  
  def forward(self, series):
    # Forward pass through LSTM layer
    # shape of lstm_out: [input_size, batch_size, hidden_dim]
    y_pred = self.linear(series.cuda())
    return y_pred.view(-1)

criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
hist = np.zeros(NUM_EPOCHS)
model = LSTMTimeSeries(INPUT_DIM, HIDDEN_DIM, BATCH_SIZE, OUTPUT_DIM, NUM_LAYERS)

# train(NUM_EPOCHS, train_tensor, target_tensor, model, optimizer, hist):

#####################
# Train model
#####################

for t in tqdm(range(num_epochs),desc='Training...'):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(train_tensor)

    loss = loss_fn(y_pred, target_tensor)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()

# train_loss = []
# test_loss = []
# print('Beginning Training...\n')
# for i in tqdm_notebook(range(NUM_EPOCHS), 'Training...'):
#     print('STEP: ', i)
#     def closure():
#         optimizer.zero_grad()
#         out = seq(train_tensor)
#         out = out.reshape(train_tensor.size())
#         out.values
# #         print(out)
# #         print(1,out.size())
# #         print(2,out)
# #         print(3,input_seq.size())
# #         print(4,target.size())
# #         print(5,target)
#         loss = criterion(out, target)
#         print('loss:', loss.item())
#         loss.backward()
#         return loss
#     optimizer.step(closure)
#     # begin to predict, no need to track gradient here
#     print('Beginning Predictions...')
#     with torch.no_grad():
#         pred = seq(test, future=FUTURE)
# #         print('pred shape', pred.size())
# #         print('pred',pred)
# #         print('pred[:, :-future] shape', pred[:, :-future].size())
# #         print('pred[:, :-future]',pred[:, :-future])
# #         print('test_target shape', test_target.size())
# #         print('test_target',test_target)
# #         print(test.size())
  
#         loss = criterion(pred[:, :-FUTURE].reshape(test.size()), test_target)
#         pred = pred[:, :-FUTURE].reshape(test.size())
    
# #         print('test loss:', loss.item())
# #         print('pred.shape', pred.shape)
# #         y = pred.detach().numpy()
#         y = pred.detach()
# #         print(type(y))
# #         print('y_before',y)
#         y = np.array([inverse_normalize_df(series, ts_scaler) for series in y])
#         print('y_after',y)

"""# **Summary**

## Work Completed
- Created a 2 cell LSTM neural network which takes 4 features from the SUMO simulation dataset. 
- Adapted a single dimension neural network to multi-dimension neural network.
- Generated readable output with decreasing train and test loss.
- Explored many ways in how not to implement a neural network in PyTorch (through trial and error...)

## Prediction Notes:
- There are negative values within the prediction.
- The loss trails off very quickly after 2-3 epochs
- What should the prediction tensor look like (what dimensions)?

## General Questions:
- How to remove negative values?
- How to improve accuracy?
- How to improve the learning of the values?-
- How to test the learning of the neural network? 
- How confident can we say the network is learning the nonlinearity of the sequence?

## LSTM Questions
- How do additional layers affect the accuracy?
- How do additional features affect the accuracy?
- How does chaning the `HIDDEN_DIM` change the accuracy of the predictions?

## Future
"""

